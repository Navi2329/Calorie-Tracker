{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-24T12:29:48.818825Z","iopub.status.busy":"2024-05-24T12:29:48.818448Z","iopub.status.idle":"2024-05-24T12:30:20.804588Z","shell.execute_reply":"2024-05-24T12:30:20.803246Z","shell.execute_reply.started":"2024-05-24T12:29:48.818795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ultralytics==8.0.196 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (8.0.196)\n","Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (3.9.0)\n","Requirement already satisfied: numpy>=1.22.2 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (4.10.0.82)\n","Requirement already satisfied: pillow>=7.1.2 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (10.2.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (2.32.0)\n","Requirement already satisfied: scipy>=1.4.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (1.13.0)\n","Requirement already satisfied: torch>=1.8.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (4.66.4)\n","Requirement already satisfied: pandas>=1.1.4 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (0.13.2)\n","Requirement already satisfied: psutil in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (5.9.8)\n","Requirement already satisfied: py-cpuinfo in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (9.0.0)\n","Requirement already satisfied: thop>=0.1.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from ultralytics==8.0.196) (0.1.1.post2209072238)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (0.10.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.196) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.196) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.196) (2023.7.22)\n","Requirement already satisfied: filelock in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (4.9.0)\n","Requirement already satisfied: sympy in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (3.1.3)\n","Requirement already satisfied: fsspec in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (2024.2.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.196) (2021.4.0)\n","Requirement already satisfied: colorama in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.0.196) (0.4.6)\n","Requirement already satisfied: six in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics==8.0.196) (1.16.0)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics==8.0.196) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics==8.0.196) (2021.11.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.0.196) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\navan\\envs\\ml\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics==8.0.196) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: The candidate selected for download or install is a yanked version: 'opencv-python-headless' candidate (version 4.8.0.74 at https://files.pythonhosted.org/packages/60/e7/a6dedca760db7a4686fd3b6053487ad4ad4d8f0591295dc8a9cf35269c42/opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl (from https://pypi.org/simple/opencv-python-headless/) (requires-python:>=3.6))\n","Reason for being yanked: deprecated, use 4.8.0.76\n"]}],"source":["# %pip install ultralytics==8.0.196\n","# %pip install roboflow --quiet"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Jun 26 04:30:56 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0 Off |                  N/A |\n","| N/A   54C    P8              1W /   50W |      77MiB /   4096MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A      8564    C+G   ...8bbwe\\SnippingTool\\SnippingTool.exe      N/A      |\n","|    0   N/A  N/A     13192      C   ...al\\Discord\\app-1.0.9151\\Discord.exe      N/A      |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.196  Python-3.12.3 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n","Setup complete  (12 CPUs, 7.4 GB RAM, 267.4/476.1 GB disk)\n"]}],"source":["import ultralytics\n","from roboflow import Roboflow\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in Calorie-Tracker-2 to yolov8:: 100%|██████████| 1065523/1065523 [03:24<00:00, 5210.45it/s] "]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to Calorie-Tracker-2 in yolov8:: 100%|██████████| 33732/33732 [00:59<00:00, 567.99it/s]\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"Z1aUbwrIU48a7V8A0VnA\")\n","project = rf.workspace(\"calorie-tracker\").project(\"calorie-tracker-pmuck\")\n","version = project.version(2)\n","dataset = version.download(\"yolov8\")"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\navan\\Desktop\\vit materials\\VS\\PJT\\Calorie-Tracker-2\n"]}],"source":["print(dataset.location)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["New https://pypi.org/project/ultralytics/8.2.39 available 😃 Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.0.196 🚀 Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/train8/weights/last.pt, data=/teamspace/studios/this_studio/Calorie-Tracker-1/data.yaml, epochs=50, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8749747  ultralytics.nn.modules.head.Detect           [33, [320, 640, 640]]         \n","Model summary: 365 layers, 68184387 parameters, 68184371 gradients, 258.3 GFLOPs\n","\n","Transferred 595/595 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","WARNING ⚠️ NMS time limit 0.550s exceeded\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /teamspace/studios/this_studio/Calorie-Tracker-1/train/labels.ca\u001b[0m\n","WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1633, len(boxes) = 28521. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /teamspace/studios/this_studio/Calorie-Tracker-1/valid/labels.cach\u001b[0m\n","WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 319, len(boxes) = 5921. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","Plotting labels to runs/detect/train8/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00027, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","Resuming training from runs/detect/train8/weights/last.pt from epoch 21 to 50 total epochs\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train8\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/50        14G     0.8102     0.6755      1.256         45        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921       0.84      0.827      0.873      0.686\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/50        14G      0.794     0.6503      1.247         42        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.843      0.831      0.882      0.696\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/50        14G     0.7871     0.6353      1.249         45        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.846      0.834      0.879      0.692\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/50        14G     0.7852     0.6257       1.24         51        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.841      0.844      0.885        0.7\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/50      14.1G     0.7739      0.609      1.237         50        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.836      0.853      0.886      0.702\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/50      14.1G     0.7665     0.5943      1.234         61        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.838      0.855      0.885      0.701\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/50        14G     0.7575     0.5821      1.221         36        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921       0.85      0.846      0.891      0.706\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/50      14.1G     0.7484     0.5661      1.217         41        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.847      0.847      0.889      0.705\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/50        14G     0.7408     0.5494      1.208         44        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.856      0.853      0.896      0.714\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/50      14.1G     0.7317     0.5437      1.205         57        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.838      0.866      0.892       0.71\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/50      14.1G     0.7231     0.5263      1.196         51        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.847      0.859      0.896      0.714\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/50        14G     0.7157     0.5218       1.19         43        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921       0.86      0.854      0.897      0.714\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/50      14.1G     0.7038      0.504       1.19         37        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.842      0.865      0.895      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/50        14G     0.6975     0.4986      1.178         64        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.857      0.859      0.895      0.716\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/50      14.1G     0.6849     0.4824      1.174         34        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.861       0.85      0.891      0.715\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/50        14G     0.6766     0.4722      1.168         42        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.864      0.853      0.894      0.718\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/50      14.1G     0.6693     0.4583      1.158         58        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.861       0.86      0.894      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/50      14.1G     0.6584     0.4471      1.156         54        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.865      0.857      0.895      0.716\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/50      14.1G     0.6533     0.4411      1.149         37        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.858      0.863      0.894      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/50        14G     0.6433     0.4286      1.144         55        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.867      0.854      0.895      0.717\n","Closing dataloader mosaic\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/50        14G     0.5789     0.3411      1.115         23        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.854      0.872      0.894      0.716\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/50      14.1G     0.5656     0.3254      1.112         19        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.857      0.867      0.894      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/50        14G     0.5555     0.3179      1.101         45        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.868      0.855      0.893      0.715\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/50        14G     0.5509     0.3132      1.094         27        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.863      0.861      0.893      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/50      14.1G     0.5426     0.3049      1.086         22        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.868      0.854      0.892      0.715\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/50      14.1G     0.5369      0.298      1.083         58        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.861      0.862      0.891      0.715\n","Stopping training early as no improvement observed in last 10 epochs. Best results observed at epoch 36, best model saved as best.pt.\n","To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","26 epochs completed in 6.593 hours.\n","Optimizer stripped from runs/detect/train8/weights/last.pt, 136.8MB\n","Optimizer stripped from runs/detect/train8/weights/best.pt, 136.8MB\n","\n","Validating runs/detect/train8/weights/best.pt...\n","Ultralytics YOLOv8.0.196 🚀 Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 268 layers, 68155347 parameters, 0 gradients, 257.6 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all       2529       5921      0.864      0.853      0.894      0.718\n","              Biriyani       2529        165      0.946      0.855      0.952      0.793\n","                 Chole       2529        107      0.801      0.813      0.835      0.513\n","           Dal Makhani       2529        205      0.795       0.78      0.827      0.605\n","                  Dosa       2529        182      0.886      0.874      0.909      0.756\n","           Gulab Jamun       2529        225      0.963      0.936      0.981      0.864\n","                  Idly       2529        105      0.721      0.689      0.715      0.469\n","               Khichdi       2529         98      0.855        0.9      0.935      0.701\n","                 Mango       2529        197      0.922      0.929      0.978      0.844\n","               Omlette       2529        122      0.867      0.804      0.849      0.611\n","                Paapad       2529         70      0.693      0.629      0.669        0.5\n","            Plain Rice       2529        227      0.853      0.859      0.899      0.634\n","                  Poha       2529        141      0.888       0.95      0.944      0.743\n","                 Poori       2529        113      0.564      0.717      0.669      0.454\n","                 Rajma       2529         95      0.819      0.695      0.844      0.478\n","              Rasgulla       2529        273      0.925      0.904      0.961      0.805\n","                  Roti       2529        288      0.773      0.774      0.818      0.562\n","               Sambhar       2529        125      0.773      0.616      0.747      0.534\n","               Uttapam       2529        186      0.853      0.833       0.87      0.686\n","                  Vada       2529        141       0.87       0.95      0.943      0.642\n","                almond       2529        277      0.814      0.769      0.869      0.553\n","                 apple       2529        123      0.921      0.663      0.884      0.785\n","              apricots       2529        122      0.639      0.803      0.804      0.784\n","                banana       2529        335      0.965      0.994      0.993      0.878\n","          dragon fruit       2529        191      0.988      0.995      0.994      0.876\n","                grapes       2529        225      0.942       0.87      0.954      0.876\n","                 guava       2529        185      0.968      0.966      0.984      0.913\n","                orange       2529        181      0.972      0.989      0.988      0.931\n","                 peach       2529         95      0.977      0.979      0.994      0.885\n","                  pear       2529        270      0.929      0.933      0.953      0.863\n","             pineapple       2529        165      0.979      0.988      0.993      0.918\n","            strawberry       2529        279      0.947       0.96      0.984      0.865\n","           sugar apple       2529        176      0.997      0.994      0.995      0.901\n","                walnut       2529        232      0.695       0.75      0.785      0.486\n","Speed: 0.3ms preprocess, 23.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train8\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["!yolo task=detect mode=train model=yolov8x.pt data={dataset.location}/data.yaml epochs=50 cos_lr=True lr0=0.001 patience=10 plots=True"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["from ultralytics import YOLO\n","import cv2\n","import os\n","model = YOLO(\"runs/detect/train8/weights/best.pt\")"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["test = []\n","path = \"Calorie-Tracker-2/test/images\"\n","i=0\n","for img in os.listdir(path):\n","    test.append(path + \"/\" + img)\n","    i+=1\n","    if i==30:\n","        break\n","paths = []\n","for i in test:\n","    path = i.replace(\".jpg\", \"\")\n","    path = path.replace(\"images\", \"labels\")\n","    path = path + \".txt\"\n","    paths.append(path)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","0: 640x640 3 pears, 1: 640x640 3 pears, 2: 640x640 1 pear, 3: 640x640 2 pears, 4: 640x640 5 pears, 5: 640x640 1 pear, 6: 640x640 4 pears, 7: 640x640 4 pears, 8: 640x640 3 pears, 9: 640x640 1 grapes, 1 pear, 10: 640x640 3 pears, 11: 640x640 3 pears, 12: 640x640 3 pears, 13: 640x640 1 apricots, 3 pears, 14: 640x640 1 pear, 15: 640x640 1 pear, 16: 640x640 2 pears, 17: 640x640 2 pears, 18: 640x640 1 pear, 19: 640x640 1 pear, 20: 640x640 3 pears, 21: 640x640 2 Mangos, 22: 640x640 2 Dosas, 1 Sambhar, 23: 640x640 2 Dosas, 2 Sambhars, 24: 640x640 1 Dosa, 25: 640x640 1 Dosa, 1 Sambhar, 26: 640x640 1 Dosa, 1 Sambhar, 27: 640x640 2 Dosas, 28: 640x640 1 Dosa, 29: 640x640 2 Dosas, 12867.8ms\n","Speed: 4.0ms preprocess, 428.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"]}],"source":["results = model(source=test,conf=0.3,save=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[['pear', 'pear'], ['pear', 'pear', 'pear'], ['pear'], ['pear', 'pear'], ['pear', 'pear', 'pear', 'pear', 'pear', 'pear'], ['pear'], ['pear', 'pear', 'pear', 'pear'], ['pear', 'pear', 'pear', 'pear'], ['pear', 'pear'], ['pear'], ['pear', 'pear', 'pear'], ['pear', 'pear', 'pear'], ['pear', 'pear', 'pear'], ['pear', 'pear', 'pear', 'pear', 'pear', 'pear'], ['pear'], ['pear'], ['pear', 'pear'], ['pear', 'pear'], ['pear'], ['pear'], ['pear', 'pear', 'pear'], ['Mango'], ['Sambhar', 'Dosa', 'Dosa'], ['Sambhar', 'Sambhar', 'Dosa', 'Dosa'], ['Dosa'], ['Dosa', 'Sambhar'], ['Dosa'], ['Dosa', 'Dosa'], ['Dosa'], ['Dosa', 'Dosa']]\n"]}],"source":["names = results[0].names\n","labels = []\n","for i in range(len(paths)):\n","    with open(paths[i], \"r\") as file:\n","        l = []\n","        for line in file:\n","            line = line.split(\" \")\n","            label = names[int(line[0])]\n","            l.append(label)\n","        labels.append(l)\n","print(labels)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["YOLO(\n","  (model): DetectionModel(\n","    (model): Sequential(\n","      (0): Conv(\n","        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-2): 3 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (4): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-5): 6 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (5): Conv(\n","        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (6): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-5): 6 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (7): Conv(\n","        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (8): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-2): 3 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (9): SPPF(\n","        (cv1): Conv(\n","          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","      )\n","      (10): Upsample(scale_factor=2.0, mode='nearest')\n","      (11): Concat()\n","      (12): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-2): 3 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (13): Upsample(scale_factor=2.0, mode='nearest')\n","      (14): Concat()\n","      (15): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-2): 3 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (16): Conv(\n","        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (17): Concat()\n","      (18): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-2): 3 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (19): Conv(\n","        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): SiLU(inplace=True)\n","      )\n","      (20): Concat()\n","      (21): C2f(\n","        (cv1): Conv(\n","          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (cv2): Conv(\n","          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): ModuleList(\n","          (0-2): 3 x Bottleneck(\n","            (cv1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (cv2): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (22): Detect(\n","        (cv2): ModuleList(\n","          (0): Sequential(\n","            (0): Conv(\n","              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (1): Conv(\n","              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","          (1-2): 2 x Sequential(\n","            (0): Conv(\n","              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (1): Conv(\n","              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","        (cv3): ModuleList(\n","          (0): Sequential(\n","            (0): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (2): Conv2d(320, 33, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","          (1-2): 2 x Sequential(\n","            (0): Conv(\n","              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (1): Conv(\n","              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): SiLU(inplace=True)\n","            )\n","            (2): Conv2d(320, 33, kernel_size=(1, 1), stride=(1, 1))\n","          )\n","        )\n","        (dfl): DFL(\n","          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","      )\n","    )\n","  )\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","metrics = model.val()\n","print(model)\n","metrics.confusion_matrix\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf = Roboflow(api_key=\"Z1aUbwrIU48a7V8A0VnA\")\n","project = rf.workspace(\"calorie-tracker\").project(\"calorie-tracker-pmuck\")\n","version = project.version(2)\n","version.deploy(model_type=\"yolov8\", model_path=\"runs/detect/train8/\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
